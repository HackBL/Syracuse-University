{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#获取HTML文本\n",
    "def getHTMLText(url):\n",
    "\ttry:\n",
    "\t\t#模拟浏览器\n",
    "\t\tkv = {'user-agent':'Mozilla/5.0'}\n",
    "\t\tr = requests.get(url, headers=kv, timeout=30)  \n",
    "\t\tr.raise_for_status()\n",
    "\t\tr.encoding = r.apparent_encoding\n",
    "\t\treturn r.text\n",
    "\texcept:\n",
    "\t\tprint(\"InternetError!\")\n",
    "\t\treturn \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解析并且返回HTML文本\n",
    "def HTMLTextconvert(html):\n",
    "\ttry:\n",
    "\t\tsoup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\t\treturn soup\n",
    "\texcept:\n",
    "\t\tprint(\"HTMLConvertError!\")\n",
    "\t\treturn \" \"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检索HTML中的信息，获取搜索排名信息\n",
    "#存在置顶的情况，需要特殊判断\n",
    "def HTMLSearch(html, ranklist):\n",
    "\tlinks = []\n",
    "\ttry:\n",
    "\t\tflag = 0\n",
    "\t\t #找到所有tbody标签下的所有内容，并且遍历所有的儿子节点\n",
    "\t\tfor tr in html.find(\"tbody\").children:\n",
    "\t\t\tif isinstance(tr, bs4.element.Tag):\n",
    "\t\t\t\tif flag==0:\n",
    "\t\t\t\t\trank = \"置顶\"\n",
    "\t\t\t\t\t#注意由于class属性会和python中的关键字重名，因此需要变为class_\n",
    "\t\t\t\t\ttd02 = tr.find_all(class_=re.compile('td-02'))\n",
    "\t\t\t\t\tfor i in td02:\n",
    "\t\t\t\t\t\t\tif isinstance(i, bs4.element.Tag):\n",
    "\t\t\t\t\t\t\t\t\t#trans得到的类型为列表\n",
    "\t\t\t\t\t\t\t\t\ttrans = i.find_all(\"a\")\n",
    "\t\t\t\t\t\t\t\t\ttrans2 = i.find('a', href=True)['href']\n",
    "\t\t\t\t\tnumber = \" \"\n",
    "\t\t\t\t\tranklist.append([rank, trans[0].string, number])\n",
    "\t\t\t\t\tlinks.append(trans2)\n",
    "\t\t\t\t\t#writer.writerow(trans[0])\n",
    "\t\t\t\t\tflag = 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t#排名信息在td标签下的class=td-01属性中\n",
    "\t\t\t\t\ttd01 = tr.find_all(class_=re.compile(\"td-01\"))\n",
    "\t\t\t\t\tfor i in td01:\n",
    "\t\t\t\t\t\t\tif isinstance(i, bs4.element.Tag):\n",
    "\t\t\t\t\t\t\t\t\trank = i.string\n",
    "\t\t\t\t\t#热搜内容和搜索量在td标签下的class=td-02属性中：内容是a标签，搜索量是span标签\n",
    "\t\t\t\t\ttd02 = tr.find_all(class_=re.compile(\"td-02\"))\n",
    "\t\t\t\t\tfor i in td02:\n",
    "\t\t\t\t\t\t\tname = i.find_all(\"a\")\n",
    "\t\t\t\t\t\t\tcolumn = i.find_all(\"span\")\n",
    "\t\t\t\t\t\t\tname2 = i.find('a', href=True)['href']\n",
    "\t\t\t\t\tranklist.append([rank, name[0].text, column[0].text])\n",
    "\t\t\t\t\t#writer.writerow(name[0])\n",
    "\t\t\t\t\tlinks.append(name2)\n",
    "\t\t\t\t\t#contents(name2)\n",
    "\t\t#return links\n",
    "\texcept:\n",
    "\t\tprint(\"HTMLSearchError!\")\n",
    "\tcontents(links,ranklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFile(df):\n",
    "    csv_file = \"/Users/boli/Desktop/export.csv\"\n",
    "\n",
    "    if not os.path.isfile(csv_file):\n",
    "        df.to_csv(csv_file, header=True, index=False, encoding = 'utf-8')\n",
    "        print(\"new\")\n",
    "    else:\n",
    "        df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "        print(\"exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveFrame(data, topics, time, data_len):\n",
    "    col_name = [\"Date\", \"Topic\", \"Comment\"]\n",
    "    df = pd.DataFrame(columns = col_name)\n",
    "\n",
    "    time_lst = []\n",
    "    topic_lst = []\n",
    "    \n",
    "    for i in range(data_len):\n",
    "        time_lst.append(time)\n",
    "        topic_lst.append(topics)\n",
    "\n",
    "    df[\"Date\"] = time_lst\n",
    "    df[\"Topic\"] = topic_lst\n",
    "    df[\"Comment\"] = data\n",
    "\n",
    "    saveFile(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/31/2020, 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def contents(links,ranklist): \n",
    "    time = datetime.now().strftime(\"%m/%d/%Y-%H:%M:%S\") # time object\n",
    "\n",
    "    # Retrieve links\n",
    "    for i in range(1,35):  #从 1 开始\n",
    "        topics = []\n",
    "        data = []\n",
    "\n",
    "        link = 'https://s.weibo.com'+links[i]\n",
    "        url = urllib.request.urlopen(link).read()\n",
    "        soup = bs4.BeautifulSoup(url,'lxml')\n",
    "\n",
    "        all_contents = soup.findAll(\"div\", {\"class\": \"content\"})\n",
    "\n",
    "        for content in all_contents:\n",
    "            if content.find(\"p\", attrs={'node-type': 'feed_list_content_full', 'class': 'txt'}):\n",
    "                expended_content = content.find(\"p\", attrs={'node-type': 'feed_list_content_full', 'class': 'txt'}).get_text().replace(\"收起全文d\", \"\")\n",
    "                data.append(expended_content)\n",
    "            else:\n",
    "                data.append(content.find(\"p\", {\"class\": \"txt\"}).get_text())\n",
    "\n",
    "        if ranklist[i][1] not in topics:\n",
    "            topics.append(ranklist[i][1])\n",
    "\n",
    "        saveFrame(data, topics, new_period, len(data))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "exist\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        #微博热搜的网站\n",
    "        url = \"https://s.weibo.com/top/summary?Refer=top_hot&topnav=1&wvr=6\"\n",
    "\n",
    "        rank = []\n",
    "        text = getHTMLText(url)\n",
    "        soup = HTMLTextconvert(text)\n",
    "        HTMLSearch(soup, rank)\n",
    "\n",
    "    except:\n",
    "        print(\"SystemError!\")\n",
    "        return 0\n",
    "\n",
    "main()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date                 Topic  \\\n",
      "0       03/10/2020-21:01:35         ['意大利紧急求助中国']   \n",
      "1       03/10/2020-21:01:35         ['意大利紧急求助中国']   \n",
      "2       03/10/2020-21:01:35         ['意大利紧急求助中国']   \n",
      "3       03/10/2020-21:01:35         ['意大利紧急求助中国']   \n",
      "4       03/10/2020-21:01:35         ['意大利紧急求助中国']   \n",
      "...                     ...                   ...   \n",
      "34144  03/31/2020, 00:00:00  ['美国监狱疫情肆虐多地在押人员抗议']   \n",
      "34145  03/31/2020, 00:00:00  ['美国监狱疫情肆虐多地在押人员抗议']   \n",
      "34146  03/31/2020, 00:00:00  ['美国监狱疫情肆虐多地在押人员抗议']   \n",
      "34147  03/31/2020, 00:00:00  ['美国监狱疫情肆虐多地在押人员抗议']   \n",
      "34148  03/31/2020, 00:00:00  ['美国监狱疫情肆虐多地在押人员抗议']   \n",
      "\n",
      "                                                 Comment  \n",
      "0      \\n                    【#加拿大航空公司暂停往返意大利航班#】加拿大航...  \n",
      "1      \\n                    【意大利紧急求助，中方将提供口罩等医疗物资】3月...  \n",
      "2      \\n                    【#意大利紧急求助中国#，王毅：将向意方提供口罩...  \n",
      "3      \\n                    【#意大利紧急求助中国# 王毅：将向意方提供口罩...  \n",
      "4      \\n#印度当街烧新冠病毒怪物塑像# 是迷信吗 尊重国家的文化 但还是要做好防护才行 #意大利...  \n",
      "...                                                  ...  \n",
      "34144  \\n                    德州的Harris County确诊人数也翻倍。...  \n",
      "34145  \\n                    【疫情播报 | 4月13日早间重要疫情消息】09...  \n",
      "34146  \\n#美国监狱疫情肆虐多地在押人员抗议#里外都不安全，啥措施也没有啊 ​          ...  \n",
      "34147  \\n#美国监狱疫情肆虐多地在押人员抗议# 当初没人预料到会严重，但是严重以后的做法才是最主要...  \n",
      "34148  \\n#美国监狱疫情肆虐多地在押人员抗议#做得不错？因为成功送某些犯人去见上帝？ ​     ...  \n",
      "\n",
      "[34149 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert csv to DF\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/Users/boli/Desktop/export.csv\")\n",
    "\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
