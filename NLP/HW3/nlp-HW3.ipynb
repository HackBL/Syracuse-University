{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139641164\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "path = \"/Users/boli/Desktop/nlp/HW3/clothing_shoes_jewelry.txt\"\n",
    "\n",
    "rfile = open(path,\"r\") \n",
    "contents = rfile.read()\n",
    "rfile.close()\n",
    "print(len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2786318\n",
      "['reviewerID:A1KLRMWW2FWPL4', 'asin:0000031887', 'reviewerName:Amazon Customer \"cameramom\"', 'helpful:[0, 0]', \"reviewText:This is a great tutu and at a really great price. It doesn't look cheap at all. I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly. A++\", 'overall:5.0', 'summary:Great tutu-  not cheaply made', 'unixReviewTime:1297468800', 'reviewTime:02 12, 2011', '']\n"
     ]
    }
   ],
   "source": [
    "lines = contents.splitlines()\n",
    "print(len(lines))\n",
    "print(lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278677\n",
      "[\"This is a great tutu and at a really great price. It doesn't look cheap at all. I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly. A++\", 'I bought this for my 4 yr old daughter for dance class, she wore it today for the first time and the teacher thought it was adorable. I bought this to go with a light blue long sleeve leotard and was happy the colors matched up great. Price was very good too since some of these go for over $15.00 dollars.', 'What can I say... my daughters have it in orange, black, white and pink and I am thinking to buy for they the fuccia one. It is a very good way for exalt a dancer outfit: great colors, comfortable, looks great, easy to wear, durables and little girls love it. I think it is a great buy for costumer and play too.']\n"
     ]
    }
   ],
   "source": [
    "# Remove title \"reviewText:\"\n",
    "reviewText = [r[11:] for r in lines if \"reviewText\" in r ] # r[11:] is contents after 'reviewText:'\n",
    "print(len(reviewText))\n",
    "print(reviewText[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88129771\n",
      "This is a great tutu and at a really great price. It doesn't look cheap at all. I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly. A++,I bought this for my 4 yr old daughter for dance class, she wore it today for the first time and the teacher thought it was ado\n"
     ]
    }
   ],
   "source": [
    "str_join = \",\".join(reviewText)\n",
    "\n",
    "print(len(str_join))\n",
    "print(str_join[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907576\n",
      "['This is a great tutu and at a really great price.', \"It doesn't look cheap at all.\", \"I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly.\", 'A++,I bought this for my 4 yr old daughter for dance class, she wore it today for the first time and the teacher thought it was adorable.', 'I bought this to go with a light blue long sleeve leotard and was happy the colors matched up great.', 'Price was very good too since some of these go for over $15.00 dollars.,What can I say... my daughters have it in orange, black, white and pink and I am thinking to buy for they the fuccia one.', 'It is a very good way for exalt a dancer outfit: great colors, comfortable, looks great, easy to wear, durables and little girls love it.', 'I think it is a great buy for costumer and play too.,We bought several tutus at once, and they are got high reviews.', 'Sturdy and seemingly well-made.', 'The girls have been wearing them regularly, including out to play, and the tutus have stood up well.', 'Fits the 3-yr old & the 5-yr old well.', 'Clearly plenty of room to grow.', 'Only con is that when the kids pull off the tutus, the waste band gets twisted, and an adult has to un-tangle.', 'But this is not difficult.,Thank you Halo Heaven great product for Little Girls.', \"My Great Grand Daughters Love these Tutu's.\", 'Will buy more from this seller.', 'Made well and cute on the girls.', \"Thanks for a great product.NEVER BUY FROM DRESS UP DREAMS........I will buy more as long as I don't buy from &#34;Dress Up Dreams&#34;  I never rec'd or order in FL.\", \"Only rec'd pink, the purple one was missing.\", 'Company is a rip off.']\n"
     ]
    }
   ],
   "source": [
    "# sentences tokenize\n",
    "textsplit = nltk.sent_tokenize(str_join)\n",
    "\n",
    "print(len(textsplit))\n",
    "print(textsplit[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['simplistic', ',', 'silly', 'and', 'tedious', '.'], 'neg')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence_polarity Corpus\n",
    "from nltk.corpus import sentence_polarity\n",
    "import random\n",
    "documents = [(sent, cat) for cat in sentence_polarity.categories() \n",
    "\tfor sent in sentence_polarity.sents(categories=cat)]\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"birot's\",\n",
       "  'directorial',\n",
       "  'debut',\n",
       "  '(',\n",
       "  'she',\n",
       "  'co-wrote',\n",
       "  'the',\n",
       "  'script',\n",
       "  'with',\n",
       "  'christophe',\n",
       "  'honoré',\n",
       "  ')',\n",
       "  \"isn't\",\n",
       "  'so',\n",
       "  'much',\n",
       "  'bad',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'bland',\n",
       "  '.'],\n",
       " 'neg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle Documents\n",
    "random.shuffle(documents)\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224073\n",
      "[\"birot's\", 'directorial', 'debut', '(', 'she', 'co-wrote', 'the', 'script', 'with', 'christophe']\n"
     ]
    }
   ],
   "source": [
    "# All Words List\n",
    "all_words_list = [word for (sent,cat) in documents for word in sent]\n",
    "print(len(all_words_list))\n",
    "print(all_words_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187486\n",
      "['directorial', 'debut', 'she', 'the', 'script', 'with', 'christophe', 'honoré', 'so', 'much']\n"
     ]
    }
   ],
   "source": [
    "# Alphabets \n",
    "alpha_words_list = [w for w in all_words_list if w.isalpha()]\n",
    "print(len(alpha_words_list))\n",
    "print(alpha_words_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statring SL_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105085"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StopWords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stop_words_list2 = [word for word in alpha_words_list if word not in stopwords]\n",
    "len(stop_words_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['film',\n",
       " 'movie',\n",
       " 'one',\n",
       " 'like',\n",
       " 'story',\n",
       " 'much',\n",
       " 'even',\n",
       " 'good',\n",
       " 'comedy',\n",
       " 'time',\n",
       " 'characters',\n",
       " 'little',\n",
       " 'way',\n",
       " 'funny',\n",
       " 'make',\n",
       " 'enough',\n",
       " 'never',\n",
       " 'makes',\n",
       " 'may',\n",
       " 'us',\n",
       " 'work',\n",
       " 'best',\n",
       " 'bad',\n",
       " 'director',\n",
       " 'love',\n",
       " 'would',\n",
       " 'life',\n",
       " 'movies',\n",
       " 'well',\n",
       " 'new',\n",
       " 'could',\n",
       " 'something',\n",
       " 'really',\n",
       " 'made',\n",
       " 'performances',\n",
       " 'many',\n",
       " 'drama',\n",
       " 'films',\n",
       " 'plot',\n",
       " 'look',\n",
       " 'every',\n",
       " 'see',\n",
       " 'still',\n",
       " 'two',\n",
       " 'nothing',\n",
       " 'people',\n",
       " 'better',\n",
       " 'without',\n",
       " 'long',\n",
       " 'fun',\n",
       " 'get',\n",
       " 'action',\n",
       " 'great',\n",
       " 'though',\n",
       " 'might',\n",
       " 'big',\n",
       " 'also',\n",
       " 'another',\n",
       " 'cast',\n",
       " 'humor',\n",
       " 'first',\n",
       " 'audience',\n",
       " 'kind',\n",
       " 'sense',\n",
       " 'ever',\n",
       " 'character',\n",
       " 'performance',\n",
       " 'feels',\n",
       " 'script',\n",
       " 'far',\n",
       " 'often',\n",
       " 'thing',\n",
       " 'less',\n",
       " 'seems',\n",
       " 'minutes',\n",
       " 'real',\n",
       " 'feel',\n",
       " 'world',\n",
       " 'almost',\n",
       " 'picture',\n",
       " 'thriller',\n",
       " 'tale',\n",
       " 'quite',\n",
       " 'documentary',\n",
       " 'interesting',\n",
       " 'yet',\n",
       " 'entertaining',\n",
       " 'rather',\n",
       " 'screen',\n",
       " 'end',\n",
       " 'take',\n",
       " 'watching',\n",
       " 'full',\n",
       " 'seen',\n",
       " 'hollywood',\n",
       " 'hard',\n",
       " 'go',\n",
       " 'ultimately',\n",
       " 'heart',\n",
       " 'moments',\n",
       " 'comes',\n",
       " 'de',\n",
       " 'romantic',\n",
       " 'despite',\n",
       " 'lot',\n",
       " 'american',\n",
       " 'family',\n",
       " 'acting',\n",
       " 'original',\n",
       " 'old',\n",
       " 'find',\n",
       " 'right',\n",
       " 'gets',\n",
       " 'worth',\n",
       " 'human',\n",
       " 'takes',\n",
       " 'things',\n",
       " 'times',\n",
       " 'come',\n",
       " 'dialogue',\n",
       " 'man',\n",
       " 'actors',\n",
       " 'scenes',\n",
       " 'watch',\n",
       " 'back',\n",
       " 'material',\n",
       " 'compelling',\n",
       " 'young',\n",
       " 'music',\n",
       " 'years',\n",
       " 'works',\n",
       " 'emotional',\n",
       " 'think',\n",
       " 'anyone',\n",
       " 'seem',\n",
       " 'want',\n",
       " 'gives',\n",
       " 'least',\n",
       " 'know',\n",
       " 'going',\n",
       " 'say',\n",
       " 'part',\n",
       " 'sometimes',\n",
       " 'piece',\n",
       " 'cinematic',\n",
       " 'entertainment',\n",
       " 'kids',\n",
       " 'give',\n",
       " 'subject',\n",
       " 'last',\n",
       " 'point',\n",
       " 'pretty',\n",
       " 'bit',\n",
       " 'special',\n",
       " 'keep',\n",
       " 'making',\n",
       " 'dull',\n",
       " 'cinema',\n",
       " 'whole',\n",
       " 'together',\n",
       " 'fascinating',\n",
       " 'anything',\n",
       " 'fans',\n",
       " 'year',\n",
       " 'away',\n",
       " 'moving',\n",
       " 'since',\n",
       " 'need',\n",
       " 'manages',\n",
       " 'style',\n",
       " 'star',\n",
       " 'true',\n",
       " 'laughs',\n",
       " 'show',\n",
       " 'experience',\n",
       " 'always',\n",
       " 'sweet',\n",
       " 'clever',\n",
       " 'offers',\n",
       " 'history',\n",
       " 'simply',\n",
       " 'high',\n",
       " 'direction',\n",
       " 'mr',\n",
       " 'dark',\n",
       " 'silly',\n",
       " 'instead',\n",
       " 'charm',\n",
       " 'whose',\n",
       " 'care',\n",
       " 'predictable',\n",
       " 'actually',\n",
       " 'art',\n",
       " 'visual',\n",
       " 'flick',\n",
       " 'nearly',\n",
       " 'everything',\n",
       " 'title',\n",
       " 'matter',\n",
       " 'series']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Frequency Word with 2000\n",
    "all_words2 = nltk.FreqDist(stop_words_list2)\n",
    "word_items2 = all_words2.most_common(2000)\n",
    "word_features2 = [word for (word,count) in word_items2]\n",
    "word_features2[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLpath = 'subjclueslen1-HLTEMNLP05.tff'\n",
    "def readSubjectivity(path):\n",
    "    flexicon = open(path, 'r')\n",
    "    # initialize an empty dictionary\n",
    "    sldict = { }\n",
    "    for line in flexicon:\n",
    "        fields = line.split()   # default is to split on whitespace\n",
    "        # split each field on the '=' and keep the second part as the value\n",
    "        strength = fields[0].split(\"=\")[1]\n",
    "        word = fields[2].split(\"=\")[1]\n",
    "        posTag = fields[3].split(\"=\")[1]\n",
    "        stemmed = fields[4].split(\"=\")[1]\n",
    "        polarity = fields[5].split(\"=\")[1]\n",
    "        if (stemmed == 'y'):\n",
    "            isStemmed = True\n",
    "        else:\n",
    "            isStemmed = False\n",
    "        # put a dictionary entry with the word as the keyword\n",
    "        #     and a list of the other values\n",
    "        sldict[word] = [strength, posTag, isStemmed, polarity]\n",
    "    return sldict\n",
    "SL = readSubjectivity(SLpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SL_features(document, word_features, SL):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    # count variables for the 4 classes of subjectivity\n",
    "    weakPos = 0\n",
    "    strongPos = 0\n",
    "    weakNeg = 0\n",
    "    strongNeg = 0\n",
    "    for word in document_words:\n",
    "        if word in SL:\n",
    "            strength, posTag, isStemmed, polarity = SL[word]\n",
    "            if strength == 'weaksubj' and polarity == 'positive':\n",
    "                weakPos += 1\n",
    "            if strength == 'strongsubj' and polarity == 'positive':\n",
    "                strongPos += 1\n",
    "            if strength == 'weaksubj' and polarity == 'negative':\n",
    "                weakNeg += 1\n",
    "            if strength == 'strongsubj' and polarity == 'negative':\n",
    "                strongNeg += 1\n",
    "            features['positivecount'] = weakPos + (2 * strongPos)\n",
    "            features['negativecount'] = weakNeg + (2 * strongNeg)      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_featuresets = [(SL_features(d, word_features2, SL), c) for (d, c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.762"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set2, test_set2 = SL_featuresets[1000:], SL_featuresets[:1000]\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "nltk.classify.accuracy(classifier2, test_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    contains(engrossing) = True              pos : neg    =     21.5 : 1.0\n",
      "          contains(warm) = True              pos : neg    =     19.5 : 1.0\n",
      "      contains(mediocre) = True              neg : pos    =     16.5 : 1.0\n",
      "       contains(routine) = True              neg : pos    =     16.5 : 1.0\n",
      "       contains(generic) = True              neg : pos    =     15.1 : 1.0\n",
      "     contains(inventive) = True              pos : neg    =     14.9 : 1.0\n",
      "          contains(dull) = True              neg : pos    =     14.5 : 1.0\n",
      "    contains(refreshing) = True              pos : neg    =     14.2 : 1.0\n",
      "        contains(boring) = True              neg : pos    =     13.7 : 1.0\n",
      "          contains(flat) = True              neg : pos    =     13.1 : 1.0\n",
      "      contains(powerful) = True              pos : neg    =     12.0 : 1.0\n",
      "          contains(lame) = True              neg : pos    =     11.8 : 1.0\n",
      "      contains(captures) = True              pos : neg    =     11.3 : 1.0\n",
      "         contains(waste) = True              neg : pos    =     11.1 : 1.0\n",
      " contains(extraordinary) = True              pos : neg    =     10.9 : 1.0\n",
      "     contains(wonderful) = True              pos : neg    =     10.9 : 1.0\n",
      "  contains(refreshingly) = True              pos : neg    =     10.9 : 1.0\n",
      "      contains(haunting) = True              pos : neg    =     10.9 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =     10.7 : 1.0\n",
      "         contains(stale) = True              neg : pos    =     10.4 : 1.0\n",
      "      contains(tiresome) = True              neg : pos    =     10.4 : 1.0\n",
      "      contains(chilling) = True              pos : neg    =     10.2 : 1.0\n",
      "      contains(provides) = True              pos : neg    =     10.1 : 1.0\n",
      "        contains(beauty) = True              pos : neg    =     10.1 : 1.0\n",
      "         contains(worse) = True              neg : pos    =      9.9 : 1.0\n",
      "        contains(devoid) = True              neg : pos    =      9.8 : 1.0\n",
      "        contains(unless) = True              neg : pos    =      9.8 : 1.0\n",
      "      contains(mindless) = True              neg : pos    =      9.8 : 1.0\n",
      "       contains(intense) = True              pos : neg    =      9.6 : 1.0\n",
      "      contains(disaster) = True              neg : pos    =      9.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier2.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It isn't a &#34;full&#34; or high quality skirt, but it is perfect for my daughter to wear over leggings for her little outfits.,My daughter liked this, and it with her costume, but she would have liked it to be a bit fuller.,For what I paid for two tutus is unbeatable anywhere!\", 'I ordered a pink and turquios and they are vibrant and beautiful!', 'Princess style!', 'I paid less than 7 bucks for a tutu I and I feel proud of my self for researching to the point of finding gold!Recommend 2-6 years!My daughter is two !', 'Wears size 4t and this skirt ( one size ) fit perfect and will probaly be able to accommodate her quickly growing waist for some time!,Wonder my niece wears it every single day, yellow is her favorite color right now an this cute little tutu made he da.']\n",
      "[\"Thanks for a great product.NEVER BUY FROM DRESS UP DREAMS........I will buy more as long as I don't buy from &#34;Dress Up Dreams&#34;  I never rec'd or order in FL.\", \"Only rec'd pink, the purple one was missing.\", 'Company is a rip off.', \"REFUSES to make good on purchase...... Real creeps.,I received this today and I'm not a fan of it but my daughter is I thought it would be puffier as it looks in the pic but it's not and the one they sent me is pink underneath and the waist band is pink which is not what I wanted due to the fact she already had the sandals she was gonna wear with it now I gotta find another pair of sandals,ima just keep it cuz she likes it.,Bought this as a backup to the regular ballet outfit my daughter has to wear.\", 'The tutu is very full!']\n"
     ]
    }
   ],
   "source": [
    "# RESULT\n",
    "pos2 = []\n",
    "neg2 = []\n",
    "\n",
    "for text in textsplit:  \n",
    "    texttokens = nltk.word_tokenize(text)\n",
    "    inputfeatureset = SL_features(texttokens, word_features2, SL)\n",
    "    \n",
    "    if classifier2.classify(inputfeatureset) == 'pos':\n",
    "        pos2.append(text)\n",
    "    elif classifier2.classify(inputfeatureset) == 'neg':\n",
    "        neg2.append(text)\n",
    "                \n",
    "print(pos2[10:15])\n",
    "print(neg2[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg--------------------------------\n",
      "463424\n",
      "[\"It doesn't look cheap at all.\", \"I'm so glad I looked on Amazon and found such an affordable tutu that isn't made poorly.\", 'Price was very good too since some of these go for over $15.00 dollars.,What can I say... my daughters have it in orange, black, white and pink and I am thinking to buy for they the fuccia one.', 'I think it is a great buy for costumer and play too.,We bought several tutus at once, and they are got high reviews.', 'Sturdy and seemingly well-made.']\n",
      "\n",
      "pos--------------------------------\n",
      "444152\n",
      "['This is a great tutu and at a really great price.', 'A++,I bought this for my 4 yr old daughter for dance class, she wore it today for the first time and the teacher thought it was adorable.', 'I bought this to go with a light blue long sleeve leotard and was happy the colors matched up great.', 'It is a very good way for exalt a dancer outfit: great colors, comfortable, looks great, easy to wear, durables and little girls love it.', 'The girls have been wearing them regularly, including out to play, and the tutus have stood up well.']\n"
     ]
    }
   ],
   "source": [
    "print(\"neg--------------------------------\")\n",
    "print(len(neg2))\n",
    "print(neg2[:5])\n",
    "\n",
    "print(\"\\npos--------------------------------\")\n",
    "print(len(pos2))\n",
    "print(pos2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Pos  \\\n",
      "0   This is a great tutu and at a really great price.   \n",
      "1   A++,I bought this for my 4 yr old daughter for...   \n",
      "2   I bought this to go with a light blue long sle...   \n",
      "3   It is a very good way for exalt a dancer outfi...   \n",
      "4   The girls have been wearing them regularly, in...   \n",
      "..                                                ...   \n",
      "95                       Do you think that will work?   \n",
      "96  Neither do I.,If you really need to learn a ne...   \n",
      "97  But by far, the fastest way to a new language ...   \n",
      "98  But I do love learning languages and I really ...   \n",
      "99                            And actual fun lessons.   \n",
      "\n",
      "                                                  Neg  \n",
      "0                       It doesn't look cheap at all.  \n",
      "1   I'm so glad I looked on Amazon and found such ...  \n",
      "2   Price was very good too since some of these go...  \n",
      "3   I think it is a great buy for costumer and pla...  \n",
      "4                     Sturdy and seemingly well-made.  \n",
      "..                                                ...  \n",
      "95  You run the application and learning CD's thro...  \n",
      "96  I have learned languages(the Romance languages...  \n",
      "97  It's a fine start, but if you're serious, you'...  \n",
      "98  Your call!May I suggest, for quick learning, s...  \n",
      "99  I have 7 years of high school and college Fren...  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Table\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "col_name = [\"Pos\", \"Neg\"]\n",
    "df = pd.DataFrame(columns = col_name)\n",
    "\n",
    "df[\"Pos\"] = pos2[:100]\n",
    "df[\"Neg\"] = neg2[:100]\n",
    "\n",
    "csv_file = \"/Users/boli/Desktop/nlp/HW3/SL_table.csv\"\n",
    "\n",
    "if not os.path.isfile(csv_file):\n",
    "    df.to_csv(csv_file, header=True, index=False, encoding = 'utf-8')\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos into file \n",
    "posFile = open('/Users/boli/Desktop/nlp/HW3/SL_feature_pos.txt', 'w')\n",
    "for r in pos2:\n",
    "    posFile.write(r + '\\n')\n",
    "posFile.close()\n",
    "\n",
    "# neg into file \n",
    "negFile = open('/Users/boli/Desktop/nlp/HW3/SL_feature_neg.txt', 'w')\n",
    "for r in neg2:\n",
    "    negFile.write(r + '\\n')\n",
    "negFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ending SL_Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statring NON_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negation Words\n",
    "# this list of negation words includes some \"approximate negators\" like hardly and rarely\n",
    "negationwords = ['no', 'not', 'never', 'none', 'nowhere', 'nothing', 'noone', 'rather', 'hardly', 'scarcely', 'rarely', 'seldom', 'neither', 'nor',\n",
    "                'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106321"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# StopWords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newstopwords = [word for word in stopwords if word not in negationwords]\n",
    "stop_words_list = [word for word in alpha_words_list if word not in newstopwords]\n",
    "len(stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['film',\n",
       " 'movie',\n",
       " 'not',\n",
       " 'one',\n",
       " 'like',\n",
       " 'story',\n",
       " 'no',\n",
       " 'much',\n",
       " 'even',\n",
       " 'good',\n",
       " 'comedy',\n",
       " 'time',\n",
       " 'characters',\n",
       " 'little',\n",
       " 'way',\n",
       " 'funny',\n",
       " 'make',\n",
       " 'enough',\n",
       " 'never',\n",
       " 'makes',\n",
       " 'may',\n",
       " 'us',\n",
       " 'work',\n",
       " 'best',\n",
       " 'bad',\n",
       " 'director',\n",
       " 'love',\n",
       " 'would',\n",
       " 'life',\n",
       " 'movies',\n",
       " 'well',\n",
       " 'new',\n",
       " 'could',\n",
       " 'something',\n",
       " 'really',\n",
       " 'made',\n",
       " 'performances',\n",
       " 'drama',\n",
       " 'many',\n",
       " 'plot',\n",
       " 'look',\n",
       " 'films',\n",
       " 'still',\n",
       " 'every',\n",
       " 'see',\n",
       " 'two',\n",
       " 'nothing',\n",
       " 'people',\n",
       " 'better',\n",
       " 'long',\n",
       " 'without',\n",
       " 'fun',\n",
       " 'get',\n",
       " 'action',\n",
       " 'great',\n",
       " 'though',\n",
       " 'might',\n",
       " 'big',\n",
       " 'also',\n",
       " 'another',\n",
       " 'cast',\n",
       " 'humor',\n",
       " 'first',\n",
       " 'audience',\n",
       " 'kind',\n",
       " 'sense',\n",
       " 'ever',\n",
       " 'character',\n",
       " 'performance',\n",
       " 'feels',\n",
       " 'script',\n",
       " 'far',\n",
       " 'often',\n",
       " 'thing',\n",
       " 'less',\n",
       " 'seems',\n",
       " 'minutes',\n",
       " 'real',\n",
       " 'feel',\n",
       " 'thriller',\n",
       " 'almost',\n",
       " 'world',\n",
       " 'tale',\n",
       " 'picture',\n",
       " 'quite',\n",
       " 'documentary',\n",
       " 'interesting',\n",
       " 'yet',\n",
       " 'entertaining',\n",
       " 'screen',\n",
       " 'rather',\n",
       " 'end',\n",
       " 'watching',\n",
       " 'take',\n",
       " 'full',\n",
       " 'hollywood',\n",
       " 'seen',\n",
       " 'hard',\n",
       " 'go',\n",
       " 'ultimately',\n",
       " 'heart',\n",
       " 'moments',\n",
       " 'romantic',\n",
       " 'de',\n",
       " 'comes',\n",
       " 'lot',\n",
       " 'despite',\n",
       " 'american',\n",
       " 'acting',\n",
       " 'family',\n",
       " 'original',\n",
       " 'old',\n",
       " 'find',\n",
       " 'right',\n",
       " 'gets',\n",
       " 'worth',\n",
       " 'human',\n",
       " 'takes',\n",
       " 'things',\n",
       " 'times',\n",
       " 'come',\n",
       " 'dialogue',\n",
       " 'man',\n",
       " 'scenes',\n",
       " 'actors',\n",
       " 'back',\n",
       " 'watch',\n",
       " 'material',\n",
       " 'compelling',\n",
       " 'young',\n",
       " 'music',\n",
       " 'years',\n",
       " 'works',\n",
       " 'think',\n",
       " 'emotional',\n",
       " 'anyone',\n",
       " 'seem',\n",
       " 'want',\n",
       " 'gives',\n",
       " 'least',\n",
       " 'going',\n",
       " 'know',\n",
       " 'say',\n",
       " 'part',\n",
       " 'piece',\n",
       " 'sometimes',\n",
       " 'entertainment',\n",
       " 'cinematic',\n",
       " 'last',\n",
       " 'kids',\n",
       " 'point',\n",
       " 'pretty',\n",
       " 'give',\n",
       " 'subject',\n",
       " 'special',\n",
       " 'bit',\n",
       " 'keep',\n",
       " 'making',\n",
       " 'together',\n",
       " 'fascinating',\n",
       " 'dull',\n",
       " 'cinema',\n",
       " 'whole',\n",
       " 'fans',\n",
       " 'anything',\n",
       " 'year',\n",
       " 'away',\n",
       " 'since',\n",
       " 'moving',\n",
       " 'manages',\n",
       " 'style',\n",
       " 'need',\n",
       " 'true',\n",
       " 'laughs',\n",
       " 'show',\n",
       " 'star',\n",
       " 'clever',\n",
       " 'sweet',\n",
       " 'always',\n",
       " 'experience',\n",
       " 'history',\n",
       " 'offers',\n",
       " 'simply',\n",
       " 'direction',\n",
       " 'high',\n",
       " 'mr',\n",
       " 'silly',\n",
       " 'dark',\n",
       " 'instead',\n",
       " 'charm',\n",
       " 'care',\n",
       " 'whose',\n",
       " 'actually',\n",
       " 'predictable',\n",
       " 'everything',\n",
       " 'nearly',\n",
       " 'flick',\n",
       " 'art',\n",
       " 'visual',\n",
       " 'around']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Frequency Word with 2000\n",
    "all_words = nltk.FreqDist(stop_words_list)\n",
    "word_items = all_words.most_common(2000)\n",
    "word_features = [word for (word,count) in word_items]\n",
    "word_features[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Not Feature\n",
    "def NOT_features(document, word_features, negationwords):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = False\n",
    "        features['contains(NOT{})'.format(word)] = False\n",
    "    # go through document words in order\n",
    "    for i in range(0, len(document)):\n",
    "        word = document[i]\n",
    "        if ((i + 1) < len(document)) and ((word in negationwords) or (word.endswith(\"n't\"))):\n",
    "            i += 1\n",
    "            features['contains(NOT{})'.format(document[i])] = (document[i] in word_features)\n",
    "        else:\n",
    "            features['contains({})'.format(word)] = (word in word_features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not Feature Sets\n",
    "NOT_featuresets = [(NOT_features(d, word_features, negationwords), c) for (d, c) in documents]\n",
    "NOT_featuresets[0][0]['contains(NOTlike)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7968936409679234\n"
     ]
    }
   ],
   "source": [
    "# Accuracy   \"Two different sets of features\"\n",
    "train_set, test_set = NOT_featuresets[1000:], NOT_featuresets[:1000]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "nltk.classify.accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    contains(engrossing) = True              pos : neg    =     19.5 : 1.0\n",
      "         contains(waste) = True              neg : pos    =     15.8 : 1.0\n",
      "          contains(loud) = True              neg : pos    =     15.8 : 1.0\n",
      "     contains(inventive) = True              pos : neg    =     15.6 : 1.0\n",
      "      contains(mediocre) = True              neg : pos    =     15.1 : 1.0\n",
      "    contains(refreshing) = True              pos : neg    =     14.2 : 1.0\n",
      "        contains(boring) = True              neg : pos    =     14.2 : 1.0\n",
      "          contains(flat) = True              neg : pos    =     13.9 : 1.0\n",
      "       contains(routine) = True              neg : pos    =     13.8 : 1.0\n",
      "        contains(unique) = True              pos : neg    =     13.6 : 1.0\n",
      "            contains(90) = False             neg : pos    =     12.4 : 1.0\n",
      "          contains(dull) = True              neg : pos    =     12.2 : 1.0\n",
      "     contains(wonderful) = True              pos : neg    =     12.1 : 1.0\n",
      "          contains(warm) = True              pos : neg    =     11.7 : 1.0\n",
      "     contains(NOTenough) = True              neg : pos    =     11.1 : 1.0\n",
      "  contains(refreshingly) = True              pos : neg    =     10.9 : 1.0\n",
      "      contains(humanity) = True              pos : neg    =     10.9 : 1.0\n",
      "      contains(provides) = True              pos : neg    =     10.9 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =     10.7 : 1.0\n",
      "      contains(touching) = True              pos : neg    =     10.6 : 1.0\n",
      "      contains(mindless) = True              neg : pos    =     10.4 : 1.0\n",
      "         contains(stale) = True              neg : pos    =     10.4 : 1.0\n",
      " contains(extraordinary) = True              pos : neg    =     10.3 : 1.0\n",
      "          contains(ages) = True              pos : neg    =     10.3 : 1.0\n",
      "      contains(captures) = True              pos : neg    =     10.1 : 1.0\n",
      "       contains(suffers) = True              neg : pos    =      9.9 : 1.0\n",
      "          contains(save) = True              neg : pos    =      9.7 : 1.0\n",
      "         contains(bears) = True              neg : pos    =      9.7 : 1.0\n",
      "        contains(tender) = True              pos : neg    =      9.6 : 1.0\n",
      "     contains(realistic) = True              pos : neg    =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Most informative features\n",
    "classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quality is just fine for the price we paid.', 'I ordered a pink and turquios and they are vibrant and beautiful!', 'The tutu is very full!', 'Princess style!', 'I paid less than 7 bucks for a tutu I and I feel proud of my self for researching to the point of finding gold!Recommend 2-6 years!My daughter is two !']\n",
      "['Company is a rip off.', \"REFUSES to make good on purchase...... Real creeps.,I received this today and I'm not a fan of it but my daughter is I thought it would be puffier as it looks in the pic but it's not and the one they sent me is pink underneath and the waist band is pink which is not what I wanted due to the fact she already had the sandals she was gonna wear with it now I gotta find another pair of sandals,ima just keep it cuz she likes it.,Bought this as a backup to the regular ballet outfit my daughter has to wear.\", 'I was not expecting a designer skirt for this price and got exactly what I paid for.,Great tutu for a great price.', \"It isn't a &#34;full&#34; or high quality skirt, but it is perfect for my daughter to wear over leggings for her little outfits.,My daughter liked this, and it with her costume, but she would have liked it to be a bit fuller.,For what I paid for two tutus is unbeatable anywhere!\", 'Not cheaply made!']\n"
     ]
    }
   ],
   "source": [
    "# RESULT\n",
    "pos = []\n",
    "neg = []\n",
    "\n",
    "for text in textsplit:  \n",
    "    texttokens = nltk.word_tokenize(text)\n",
    "    inputfeatureset = NOT_features(texttokens, word_features, negationwords)\n",
    "    \n",
    "    if classifier.classify(inputfeatureset) == 'pos':\n",
    "        pos.append(text)\n",
    "    elif classifier.classify(inputfeatureset) == 'neg':\n",
    "        neg.append(text)\n",
    "                \n",
    "print(pos[10:15])\n",
    "print(neg[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Pos  \\\n",
      "0   This is a great tutu and at a really great price.   \n",
      "1                       It doesn't look cheap at all.   \n",
      "2   A++,I bought this for my 4 yr old daughter for...   \n",
      "3   I bought this to go with a light blue long sle...   \n",
      "4   It is a very good way for exalt a dancer outfi...   \n",
      "..                                                ...   \n",
      "95  Though I've studied two languages through clas...   \n",
      "96  I married into a Portuguese-American family an...   \n",
      "97               Then vocabulary, spoken and written.   \n",
      "98  So your learning is reinforced in three ways: ...   \n",
      "99  In later lessons you dive into conversations w...   \n",
      "\n",
      "                                                  Neg  \n",
      "0   I'm so glad I looked on Amazon and found such ...  \n",
      "1   Price was very good too since some of these go...  \n",
      "2                     Sturdy and seemingly well-made.  \n",
      "3   The girls have been wearing them regularly, in...  \n",
      "4                     Clearly plenty of room to grow.  \n",
      "..                                                ...  \n",
      "95  L'&eacute;tude du franais est r&eacute;ellemen...  \n",
      "96  Now, however, I feel like I could do OK with a...  \n",
      "97  Rosetta Stone is no substitute for deep immers...  \n",
      "98  I guess if you're *really* interested, it's wo...  \n",
      "99               Learned that in the first 5 minutes.  \n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Table\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "col_name = [\"Pos\", \"Neg\"]\n",
    "df = pd.DataFrame(columns = col_name)\n",
    "\n",
    "df[\"Pos\"] = pos[:100]\n",
    "df[\"Neg\"] = neg[:100]\n",
    "\n",
    "csv_file = \"/Users/boli/Desktop/nlp/HW3/NOT_table.csv\"\n",
    "\n",
    "if not os.path.isfile(csv_file):\n",
    "    df.to_csv(csv_file, header=True, index=False, encoding = 'utf-8')\n",
    "    \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos into file \n",
    "posFile = open('/Users/boli/Desktop/nlp/HW3/NOnnT_feature_pos.txt', 'w')\n",
    "for r in pos:\n",
    "    posFile.write(r + '\\n')\n",
    "posFile.close()\n",
    "\n",
    "# neg into file \n",
    "negFile = open('/Users/boli/Desktop/nlp/HW3/NOT_feature_neg.txt', 'w')\n",
    "for r in neg:\n",
    "    negFile.write(r + '\\n')\n",
    "negFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ending NOT_Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflist = []\n",
    "testlist = []\n",
    "for (features, label) in test_set:\n",
    "    reflist.append(label)\n",
    "    testlist.append(classifier2.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflist[:30] \n",
    "testlist[:30]\n",
    "\n",
    "ref1 = set([i for i,label in enumerate(reflist) if label == 'pos']) \n",
    "ref2 = set([i for i,label in enumerate(reflist) if label == 'neg'])\n",
    "\n",
    "test1 = set([i for i,label in enumerate(testlist) if label == 'pos']) \n",
    "test2 = set([i for i,label in enumerate(testlist) if label == 'neg'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos precision: 0.7334887334887334\n",
      "pos recall: 0.7039522744220731\n",
      "pos F-measure: 0.7184170471841705\n",
      "\n",
      "neg precision: 0.712005803409503\n",
      "neg recall: 0.7410343525858815\n",
      "neg F-measure: 0.7262301146873843\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import *\n",
    "\n",
    "def printmeasures(label, refset, testset):\n",
    "    print(label, 'precision:', precision(refset, testset))\n",
    "    print(label, 'recall:', recall(refset, testset)) \n",
    "    print(label, 'F-measure:', f_measure(refset, testset))\n",
    "\n",
    "printmeasures('pos', ref1, test1) \n",
    "print()\n",
    "printmeasures('neg', ref2, test2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
